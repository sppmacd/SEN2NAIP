train:
  mode: ""
  batch_size: 2
  gradient_accumulation_steps: 8
  optimizer: "adam"
  loss: "L1"
  max_epochs: 20
  tb_log_dir: "test_full"
